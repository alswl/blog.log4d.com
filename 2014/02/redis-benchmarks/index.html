<!DOCTYPE html><html lang=en> <head><title>Redis 到底有多快[译文] - Log4D</title><!-- Using the latest rendering mode for IE --><meta http-equiv=X-UA-Compatible content="IE=edge"><meta charset=utf-8><meta name=viewport content="width=device-width, initial-scale=1.0"><meta http-equiv=Content-Security-Policy content=block-all-mixed-content><link rel="shortcut icon" href=/favicon.ico type=image/x-icon><link href=https://blog.alswl.com/2014/02/redis-benchmarks/ rel=canonical><meta name=author content=alswl><meta name=keywords content=性能,Redis,benchmark,译文><meta name=description content="原文地址 http://redis.io/topics/benchmarks。 拖了一个半月的稿子~ Redis 自带了一个叫 redis-benchmark 的工具来模拟 N 个客户端同时发出 M 个请求。 （类似于 Apache ab 程序）。你可以使用 redis-benchmark -h 来查看基准参数。"><!-- Bootstrap --><link rel=stylesheet href=https://blog.alswl.com/theme/css/bootstrap.min.css type=text/css><link href=https://blog.alswl.com/theme/css/font-awesome.min.css rel=stylesheet><link href=https://blog.alswl.com/theme/css/pygments/native.css rel=stylesheet><link rel=stylesheet href=https://blog.alswl.com/theme/css/style.css type=text/css><link href=https://blog.alswl.com/atom.xml type=application/atom+xml rel=alternate title="Log4D Atom Feed"><link href=https://blog.alswl.com/rss.xml type=application/rss+xml rel=alternate title="Log4D RSS Feed"></head> <body> <div class="navbar navbar-default" role=navigation> <div class="container  col-lg-8 col-lg-offset-2"> <div class=navbar-header> <button type=button class=navbar-toggle data-toggle=collapse data-target=.navbar-ex1-collapse> <span class=sr-only>Toggle navigation</span> <span class=icon-bar></span> <span class=icon-bar></span> <span class=icon-bar></span> </button> <a href=https://blog.alswl.com/ class=navbar-brand> Log4D </a> </div> <div class="collapse navbar-collapse navbar-ex1-collapse"> <ul class="nav navbar-nav"> <li><a href=/tags/ >Tags</a></li> <li><a href=/links/ >Links</a></li> <li><a href=/about/ >About</a></li> </ul> <ul class="nav navbar-nav navbar-right"> <li><a href=https://blog.alswl.com/archives/ ><i class="fa fa-th-list"></i><span class=icon-label>Archives</span></a></li> </ul> </div> <!-- /.navbar-collapse --> </div> </div> <!-- /.navbar --> <div class=container> <div class=row> <div class="col-lg-8 col-lg-offset-2"> <section id=content> <article class=article-detail> <header class=page-header> <h1 class=title> <a href=https://blog.alswl.com/2014/02/redis-benchmarks/ rel=bookmark title="Permalink to Redis 到底有多快[译文]"> Redis 到底有多快[译文] </a> </h1> </header> <div class=entry-content> <div class=panel> <div class=panel-body> <footer class=post-info> <span class="label label-default">Date</span> <span class=published> <i class="fa fa-calendar"></i><time datetime=2014-02-23T22:38:00> 2014-02-23</time> </span> <span class="label label-default">Tags</span> <a href=https://blog.alswl.com/tag/xing-neng/ >性能</a> / <a href=https://blog.alswl.com/tag/redis/ >Redis</a> / <a href=https://blog.alswl.com/tag/benchmark/ >benchmark</a> / <a href=https://blog.alswl.com/tag/yi-wen/ >译文</a> </footer><!-- /.post-info --> </div> </div> <nav class=toc> <div id=toc><ul><li><a class=toc-href href=#zhi-yun-xing-yi-xie-ce-shi-yong-li-de-zi-ji title=只运行一些测试用例的子集>只运行一些测试用例的子集</a></li><li><a class=toc-href href=#xuan-ze-ce-shi-jian-de-fan-wei-da-xiao title=选择测试键的范围大小>选择测试键的范围大小</a></li><li><a class=toc-href href=#shi-yong-pipelining title="使用 pipelining">使用 pipelining</a></li><li><a class=toc-href href=#xian-jing-he-cuo-wu-de-ren-shi title=陷阱和错误的认识>陷阱和错误的认识</a></li><li><a class=toc-href href=#ying-xiang-redis-xing-neng-de-yin-su title="影响 Redis 性能的因素">影响 Redis 性能的因素</a></li><li><a class=toc-href href=#qi-ta-xu-yao-zhu-yi-de-dian title=其他需要注意的点>其他需要注意的点</a></li><li><a class=toc-href href=#geng-duo-shi-yong-pipeline-de-ce-shi title="更多使用 pipeline 的测试">更多使用 pipeline 的测试</a></li></ul></div> </nav> <p>原文地址 <a href=http://redis.io/topics/benchmarks>http://redis.io/topics/benchmarks</a>。</p> <p>拖了一个半月的稿子~</p> <hr> <p>Redis 自带了一个叫 <code>redis-benchmark</code> 的工具来模拟 N 个客户端同时发出 M 个请求。 （类似于 Apache <code>ab</code> 程序）。你可以使用 <code>redis-benchmark -h</code> 来查看基准参数。</p> <div class=highlight><pre><span class=err>以下参数被支持：</span>

    <span class=nb>Usage</span><span class=p>:</span> <span class=nx>redis</span><span class=na>-benchmark</span> <span class=err>[</span><span class=na>-h</span> <span class=o>&lt;</span><span class=nb>host</span><span class=o>&gt;</span><span class=cp>]</span> <span class=cp>[</span><span class=na>-p</span> <span class=o>&lt;</span><span class=nb>port</span><span class=o>&gt;</span><span class=cp>]</span> <span class=cp>[</span><span class=na>-c</span> <span class=o>&lt;</span><span class=nx>clients</span><span class=o>&gt;</span><span class=cp>]</span> <span class=cp>[</span><span class=na>-n</span> <span class=o>&lt;</span><span class=nx>requests</span><span class=cp>]</span>&gt; <span class=cp>[</span><span class=na>-k</span> <span class=o>&lt;</span><span class=nb>boolean</span><span class=o>&gt;</span><span class=cp>]</span>

     -h <span class=nt>&lt;hostname&gt;</span>      Server hostname (default 127.0.0.1)
     -p <span class=nt>&lt;port&gt;</span>          Server port (default 6379)
     -s <span class=nt>&lt;socket&gt;</span>        Server socket (overrides host and port)
     -c <span class=nt>&lt;clients&gt;</span>       Number of parallel connections (default 50)
     -n <span class=nt>&lt;requests&gt;</span>      Total number of requests (default 10000)
     -d <span class=nt>&lt;size&gt;</span>          Data size of SET/GET value in bytes (default 2)
     -k <span class=nt>&lt;boolean&gt;</span>       1=keep alive 0=reconnect (default 1)
     -r <span class=nt>&lt;keyspacelen&gt;</span>   Use random keys for SET/GET/INCR, random values for SADD
      Using this option the benchmark will get/set keys
      in the form mykey_rand:000000012456 instead of constant
      keys, the <span class=nt>&lt;keyspacelen&gt;</span> argument determines the max
      number of values for the random number. For instance
      if set to 10 only rand:000000000000 - rand:000000000009
      range will be allowed.
     -P <span class=nt>&lt;numreq&gt;</span>        Pipeline <span class=nt>&lt;numreq&gt;</span> requests. Default 1 (no pipeline).
     -q                 Quiet. Just show query/sec values
     --csv              Output in CSV format
     -l                 Loop. Run the tests forever
     -t <span class=nt>&lt;tests&gt;</span>         Only run the comma separated list of tests. The test
                        names are the same as the ones produced as output.
     -I                 Idle mode. Just open N idle connections and wait.
</pre></div> <p>你需要在基准测试之前启动一个 Redis 实例。一般这样启动测试：</p> <div class=highlight><pre><span class=n>redis</span><span class=o>-</span><span class=n>benchmark</span> <span class=o>-</span><span class=n>q</span> <span class=o>-</span><span class=n>n</span> <span class=mi>100000</span>
</pre></div> <p>这个工具使用起来非常方便，同时你可以使用自己的基准测试工具， 不过开始基准测试时候，我们需要注意一些细节。</p> <h2 id=zhi-yun-xing-yi-xie-ce-shi-yong-li-de-zi-ji>只运行一些测试用例的子集</h2> <p>你不必每次都运行 redis-benchmark 默认的所有测试。 使用 <code>-t</code> 参数可以选择你需要运行的测试用例，比如下面的范例：</p> <div class=highlight><pre><span class=err>$</span> <span class=n>redis</span><span class=o>-</span><span class=n>benchmark</span> <span class=o>-</span><span class=n>t</span> <span class=n>set</span><span class=p>,</span><span class=n>lpush</span> <span class=o>-</span><span class=n>n</span> <span class=mi>100000</span> <span class=o>-</span><span class=n>q</span>
<span class=nl>SET:</span> <span class=mf>74239.05</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>LPUSH:</span> <span class=mf>79239.30</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
</pre></div> <p>在上面的测试中，我们只运行了 SET 和 LPUSH 命令， 并且运行在安静模式中（使用 <code>-q</code> 参数）。</p> <p>也可以直接指定命令来直接运行，比如下面的范例：</p> <div class=highlight><pre><span class=err>$</span> <span class=n>redis</span><span class=o>-</span><span class=n>benchmark</span> <span class=o>-</span><span class=n>n</span> <span class=mi>100000</span> <span class=o>-</span><span class=n>q</span> <span class=n>script</span> <span class=n>load</span> <span class=s>"redis.call('set','foo','bar')"</span>
<span class=n>script</span> <span class=n>load</span> <span class=n>redis</span><span class=p>.</span><span class=n>call</span><span class=p>(</span><span class=err>'</span><span class=n>set</span><span class=sc>','</span><span class=n>foo</span><span class=sc>','</span><span class=n>bar</span><span class=err>'</span><span class=p>)</span><span class=o>:</span> <span class=mf>69881.20</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
</pre></div> <h2 id=xuan-ze-ce-shi-jian-de-fan-wei-da-xiao>选择测试键的范围大小</h2> <p>默认情况下面，基准测试使用单一的 key。在一个基于内存的数据库里， 单一 key 测试和真实情况下面不会有巨大变化。当然，使用一个大的 key 范围空间， 可以模拟现实情况下面的缓存不命中情况。</p> <p>这时候我们可以使用 <code>-r</code> 命令。比如，假设我们想设置 10 万随机 key 连续 SET 100 万次，我们可以使用下列的命令：</p> <div class=highlight><pre><span class=err>$</span> <span class=n>redis</span><span class=o>-</span><span class=n>cli</span> <span class=n>flushall</span>
<span class=n>OK</span>

<span class=err>$</span> <span class=n>redis</span><span class=o>-</span><span class=n>benchmark</span> <span class=o>-</span><span class=n>t</span> <span class=n>set</span> <span class=o>-</span><span class=n>r</span> <span class=mi>100000</span> <span class=o>-</span><span class=n>n</span> <span class=mi>1000000</span>
<span class=o>======</span> <span class=n>SET</span> <span class=o>======</span>
  <span class=mi>1000000</span> <span class=n>requests</span> <span class=n>completed</span> <span class=n>in</span> <span class=mf>13.86</span> <span class=n>seconds</span>
  <span class=mi>50</span> <span class=n>parallel</span> <span class=n>clients</span>
  <span class=mi>3</span> <span class=n>bytes</span> <span class=n>payload</span>
  <span class=n>keep</span> <span class=n>alive</span><span class=o>:</span> <span class=mi>1</span>

<span class=mf>99.76</span><span class=o>%</span> <span class=err>`</span><span class=o>&lt;=</span><span class=err>`</span> <span class=mi>1</span> <span class=n>milliseconds</span>
<span class=mf>99.98</span><span class=o>%</span> <span class=err>`</span><span class=o>&lt;=</span><span class=err>`</span> <span class=mi>2</span> <span class=n>milliseconds</span>
<span class=mf>100.00</span><span class=o>%</span> <span class=err>`</span><span class=o>&lt;=</span><span class=err>`</span> <span class=mi>3</span> <span class=n>milliseconds</span>
<span class=mf>100.00</span><span class=o>%</span> <span class=err>`</span><span class=o>&lt;=</span><span class=err>`</span> <span class=mi>3</span> <span class=n>milliseconds</span>
<span class=mf>72144.87</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>

<span class=err>$</span> <span class=n>redis</span><span class=o>-</span><span class=n>cli</span> <span class=n>dbsize</span>
<span class=p>(</span><span class=n>integer</span><span class=p>)</span> <span class=mi>99993</span>
</pre></div> <h2 id=shi-yong-pipelining>使用 pipelining</h2> <p>默认情况下，每个客户端都是在一个请求完成之后才发送下一个请求 （benchmark 会模拟 50 个客户端除非使用 <code>-c</code> 指定特别的数量）， 这意味着服务器几乎是按顺序读取每个客户端的命令。Also RTT is payed as well.</p> <p>真实世界会更复杂，Redis 支持 <a href=pipelining>/topics/pipelining</a>，使得可以一次性执行多条命令成为可能。 Redis pipelining 可以提高服务器的 TPS。</p> <p>下面这个案例是在 Macbook air 11" 上使用 pipelining 组织 16 条命令的测试范例：</p> <div class=highlight><pre><span class=err>$</span> <span class=n>redis</span><span class=o>-</span><span class=n>benchmark</span> <span class=o>-</span><span class=n>n</span> <span class=mi>1000000</span> <span class=o>-</span><span class=n>t</span> <span class=n>set</span><span class=p>,</span><span class=n>get</span> <span class=o>-</span><span class=n>P</span> <span class=mi>16</span> <span class=o>-</span><span class=n>q</span>
<span class=nl>SET:</span> <span class=mf>403063.28</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>GET:</span> <span class=mf>508388.41</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
</pre></div> <p>记得在多条命令需要处理时候使用 pipelining。</p> <h2 id=xian-jing-he-cuo-wu-de-ren-shi>陷阱和错误的认识</h2> <p>第一点是显而易见的：基准测试的黄金准则是使用相同的标准。 用相同的任务量测试不同版本的 Redis，或者用相同的参数测试测试不同版本 Redis。 如果把 Redis 和其他工具测试，那就需要小心功能细节差异。</p> <ul> <li>Redis 是一个服务器：所有的命令都包含网络或 IPC 消耗。这意味着和它和 SQLite， Berkeley DB， Tokyo/Kyoto Cabinet 等比较起来无意义， 因为大部分的消耗都在网络协议上面。</li> <li>Redis 的大部分常用命令都有确认返回。有些数据存储系统则没有（比如 MongoDB 的写操作没有返回确认）。把 Redis 和其他单向调用命令存储系统比较意义不大。</li> <li>简单的循环操作 Redis 其实不是对 Redis 进行基准测试，而是测试你的网络（或者 IPC）延迟。想要真正测试 Redis，需要使用多个连接（比如 redis-benchmark)， 或者使用 pipelining 来聚合多个命令，另外还可以采用多线程或多进程。</li> <li>Redis 是一个内存数据库，同时提供一些可选的持久化功能。 如果你想和一个持久化服务器（MySQL, PostgreSQL 等等） 对比的话， 那你需要考虑启用 AOF 和适当的 fsync 策略。</li> <li>Redis 是单线程服务。它并没有设计为多 CPU 进行优化。如果想要从多核获取好处， 那就考虑启用多个实例吧。将单实例 Redis 和多线程数据库对比是不公平的。</li> </ul> <p>一个普遍的误解是 redis-benchmark 特意让基准测试看起来更好， 所表现出来的数据像是人造的，而不是真实产品下面的。</p> <p>Redis-benchmark 程序可以简单快捷的对给定硬件条件下面的机器计算出性能参数。 但是，通常情况下面这并不是 Redis 服务器可以达到的最大吞吐量。 事实上，使用 pipelining 和更快的客户端（hiredis）可以达到更大的吞吐量。 redis-benchmark 默认情况下面仅仅使用并发来提高吞吐量（创建多条连接）。 它并没有使用 pipelining 或者其他并行技术（仅仅多条连接，而不是多线程）。</p> <p>如果想使用 pipelining 模式来进行基准测试（了达到更高吞吐量），可以使用 <code>-P</code> 参数。这种方案的确可以提高性能，有很多使用 Redis 的应用在生产环境中这样做。</p> <p>最后，基准测试需要使用相同的操作和数据来对比，如果这些不一样， 那么基准测试是无意义的。</p> <p>比如，Redis 和 memcached 可以在单线程模式下面对比 GET/SET 操作。 两者都是内存数据库，协议也基本相同，甚至把多个请求合并为一条请求的方式也类似 （pipelining）。在使用相同数量的连接后，这个对比是很有意义的。</p> <p>下面这个很不错例子是在 Redis（antirez）和 memcached（dormando）测试的。</p> <p><a href=http://antirez.com/post/redis-memcached-benchmark.html>antirez 1 - On Redis, Memcached, Speed, Benchmarks and The Toilet</a></p> <p><a href=http://dormando.livejournal.com/525147.html>dormando - Redis VS Memcached (slightly better bench)</a></p> <p><a href=http://antirez.com/post/update-on-memcached-redis-benchmark.html>antirez 2 - An update on the Memcached/Redis benchmark</a></p> <p>你可以发现相同条件下面最终结果是两者差别不大。请注意最终测试时候， 两者都经过了充分优化。</p> <p>最后，当特别高性能的服务器在基准测试时候（比如 Redis、memcached 这类）， 很难让服务器性能充分发挥，通常情况下，客户端回事瓶颈限制而不是服务器端。 在这种情况下面，客户端（比如 benchmark 程序自身）需要优化，或者使用多实例， 从而能达到最大的吞吐量。</p> <h2 id=ying-xiang-redis-xing-neng-de-yin-su>影响 Redis 性能的因素</h2> <p>有几个因素直接决定 Redis 的性能。它们能够改变基准测试的结果， 所以我们必须注意到它们。一般情况下，Redis 默认参数已经可以提供足够的性能， 不需要调优。</p> <ul> <li>网络带宽和延迟通常是最大短板。建议在基准测试之前使用 ping 来检查服务端到客户端的延迟。根据带宽，可以计算出最大吞吐量。 比如将 4 KB 的字符串塞入 Redis，吞吐量是 100000 q/s，那么实际需要 3.2 Gbits/s 的带宽，所以需要 10 GBits/s 网络连接， 1 Gbits/s 是不够的。 在很多线上服务中，Redis 吞吐会先被网络带宽限制住，而不是 CPU。 为了达到高吞吐量突破 TCP/IP 限制，最后采用 10 Gbits/s 的网卡， 或者多个 1 Gbits/s 网卡。</li> <li>CPU 是另外一个重要的影响因素，由于是单线程模型，Redis 更喜欢大缓存快速 CPU， 而不是多核。这种场景下面，比较推荐 Intel CPU。AMD CPU 可能只有 Intel CPU 的一半性能（通过对 Nehalem EP/Westmere EP/Sandy 平台的对比）。 当其他条件相当时候，CPU 就成了 redis-benchmark 的限制因素。</li> <li>在小对象存取时候，内存速度和带宽看上去不是很重要，但是对大对象（&gt; 10 KB）， 它就变得重要起来。不过通常情况下面，倒不至于为了优化 Redis 而购买更高性能的内存模块。</li> <li>Redis 在 VM 上会变慢。虚拟化对普通操作会有额外的消耗，Redis 对系统调用和网络终端不会有太多的 overhead。建议把 Redis 运行在物理机器上， 特别是当你很在意延迟时候。在最先进的虚拟化设备（VMWare）上面，redis-benchmark 的测试结果比物理机器上慢了一倍，很多 CPU 时间被消费在系统调用和中断上面。</li> <li>如果服务器和客户端都运行在同一个机器上面，那么 TCP/IP loopback 和 unix domain sockets 都可以使用。对 Linux 来说，使用 unix socket 可以比 TCP/IP loopback 快 50%。 默认 redis-benchmark 是使用 TCP/IP loopback。</li> <li>当大量使用 pipelining 时候，unix domain sockets 的优势就不那么明显了。</li> <li>当使用网络连接时，并且以太网网数据包在 1500 bytes 以下时， 将多条命令包装成 pipelining 可以大大提高效率。事实上，处理 10 bytes，100 bytes， 1000 bytes 的请求时候，吞吐量是差不多的，详细可以见下图。</li> </ul> <p><img alt="Data size impact" src=https://raw.githubusercontent.com/dspezia/redis-doc/client_command/topics/Data_size.png></p> <ul> <li>在多核 CPU 服务器上面，Redis 的性能还依赖 NUMA 配置和 处理器绑定位置。 最明显的影响是 redis-benchmark 会随机使用 CPU 内核。为了获得精准的结果， 需要使用固定处理器工具（在 Linux 上可以使用 taskset 或 numactl）。 最有效的办法是将客户端和服务端分离到两个不同的 CPU 来高校使用三级缓存。 这里有一些使用 4 KB 数据 SET 的基准测试，针对三种 CPU（AMD Istanbul, Intel Nehalem EX， 和 Intel Westmere）使用不同的配置。请注意， 这不是针对 CPU 的测试。</li> </ul> <p><img alt="NUMA chart" src=https://raw.githubusercontent.com/dspezia/redis-doc/6374a07f93e867353e5e946c1e39a573dfc83f6c/topics/NUMA_chart.gif></p> <ul> <li>在高配置下面，客户端的连接数也是一个重要的因素。得益于 epoll/kqueue， Redis 的事件循环具有相当可扩展性。Redis 已经在超过 60000 连接下面基准测试过， 仍然可以维持 50000 q/s。一条经验法则是，30000 的连接数只有 100 连接的一半吞吐量。 下面有一个关于连接数和吞吐量的测试。</li> </ul> <p><img alt="connections chart" src=https://raw.githubusercontent.com/dspezia/redis-doc/system_info/topics/Connections_chart.png></p> <ul> <li>在高配置下面，可以通过调优 NIC 来获得更高性能。最高性能在绑定 Rx/Tx 队列和 CPU 内核下面才能达到，还需要开启 RPS（网卡中断负载均衡）。更多信息可以在 <a href=https://groups.google.com/forum/#!msg/redis-db/gUhc19gnYgc/BruTPCOroiMJ>thread</a> 。Jumbo frames 还可以在大对象使用时候获得更高性能。</li> <li>在不同平台下面，Redis 可以被编译成不同的内存分配方式（libc malloc, jemalloc, tcmalloc），他们在不同速度、连续和非连续片段下会有不一样的表现。 如果你不是自己编译的 Redis，可以使用 INFO 命令来检查内存分配方式。 请注意，大部分基准测试不会长时间运行来感知不同分配模式下面的差异， 只能通过生产环境下面的 Redis 实例来查看。</li> </ul> <h2 id=qi-ta-xu-yao-zhu-yi-de-dian>其他需要注意的点</h2> <p>任何基准测试的一个重要目标是获得可重现的结果，这样才能将此和其他测试进行对比。</p> <ul> <li>一个好的实践是尽可能在隔离的硬件上面测试。如果没法实现，那就需要检测 benchmark 没有受其他服务器活动影响。</li> <li>有些配置（桌面环境和笔记本，有些服务器也会）会使用可变的 CPU 分配策略。 这种策略可以在 OS 层面配置。有些 CPU 型号相对其他能更好的调整 CPU 负载。 为了达到可重现的测试结果，最好在做基准测试时候设定 CPU 到最高使用限制。</li> <li>一个重要因素是配置尽可能大内存，千万不要使用 SWAP。注意 32 位和 64 位 Redis 有不同的内存限制。</li> <li>如果你计划在基准测试时候使用 RDB 或 AOF，请注意不要让系统同时有其他 I/O 操作。 避免将 RDB 或 AOF 文件放到 NAS 或 NFS 共享或其他依赖网络的存储设备上面（比如 Amazon EC2 上 的 EBS）。</li> <li>将 Redis 日志级别设置到 warning 或者 notice。避免将日志放到远程文件系统。</li> <li>避免使用检测工具，它们会影响基准测试结果。使用 INFO 来查看服务器状态没问题， 但是使用 MONITOR 将大大影响测试准确度。</li> </ul> <h1>不同云主机和物理机器上的基准测试结果</h1> <ul> <li>这些测试模拟了 50 客户端和 200w 请求。</li> <li>使用了 Redis 2.6.14。</li> <li>使用了 loopback 网卡。</li> <li>key 的范围是 100 w。</li> <li>同时测试了 有 pipelining 和没有的情况（16 条命令使用 pipelining）。</li> </ul> <p><strong>Intel(R) Xeon(R) CPU E5520 @ 2.27GHz (with pipelining)</strong></p> <div class=highlight><pre><span class=err>$</span> <span class=p>.</span><span class=o>/</span><span class=n>redis</span><span class=o>-</span><span class=n>benchmark</span> <span class=o>-</span><span class=n>r</span> <span class=mi>1000000</span> <span class=o>-</span><span class=n>n</span> <span class=mi>2000000</span> <span class=o>-</span><span class=n>t</span> <span class=n>get</span><span class=p>,</span><span class=n>set</span><span class=p>,</span><span class=n>lpush</span><span class=p>,</span><span class=n>lpop</span> <span class=o>-</span><span class=n>P</span> <span class=mi>16</span> <span class=o>-</span><span class=n>q</span>
<span class=nl>SET:</span> <span class=mf>552028.75</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>GET:</span> <span class=mf>707463.75</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>LPUSH:</span> <span class=mf>767459.75</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>LPOP:</span> <span class=mf>770119.38</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
</pre></div> <p><strong>Intel(R) Xeon(R) CPU E5520 @ 2.27GHz (without pipelining)</strong></p> <div class=highlight><pre><span class=err>$</span> <span class=p>.</span><span class=o>/</span><span class=n>redis</span><span class=o>-</span><span class=n>benchmark</span> <span class=o>-</span><span class=n>r</span> <span class=mi>1000000</span> <span class=o>-</span><span class=n>n</span> <span class=mi>2000000</span> <span class=o>-</span><span class=n>t</span> <span class=n>get</span><span class=p>,</span><span class=n>set</span><span class=p>,</span><span class=n>lpush</span><span class=p>,</span><span class=n>lpop</span> <span class=o>-</span><span class=n>q</span>
<span class=nl>SET:</span> <span class=mf>122556.53</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>GET:</span> <span class=mf>123601.76</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>LPUSH:</span> <span class=mf>136752.14</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>LPOP:</span> <span class=mf>132424.03</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
</pre></div> <p><strong>Linode 2048 instance (with pipelining)</strong></p> <div class=highlight><pre><span class=err>$</span> <span class=p>.</span><span class=o>/</span><span class=n>redis</span><span class=o>-</span><span class=n>benchmark</span> <span class=o>-</span><span class=n>r</span> <span class=mi>1000000</span> <span class=o>-</span><span class=n>n</span> <span class=mi>2000000</span> <span class=o>-</span><span class=n>t</span> <span class=n>get</span><span class=p>,</span><span class=n>set</span><span class=p>,</span><span class=n>lpush</span><span class=p>,</span><span class=n>lpop</span> <span class=o>-</span><span class=n>q</span> <span class=o>-</span><span class=n>P</span> <span class=mi>16</span>
<span class=nl>SET:</span> <span class=mf>195503.42</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>GET:</span> <span class=mf>250187.64</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>LPUSH:</span> <span class=mf>230547.55</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>LPOP:</span> <span class=mf>250815.16</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
</pre></div> <p><strong>Linode 2048 instance (without pipelining)</strong></p> <div class=highlight><pre><span class=err>$</span> <span class=p>.</span><span class=o>/</span><span class=n>redis</span><span class=o>-</span><span class=n>benchmark</span> <span class=o>-</span><span class=n>r</span> <span class=mi>1000000</span> <span class=o>-</span><span class=n>n</span> <span class=mi>2000000</span> <span class=o>-</span><span class=n>t</span> <span class=n>get</span><span class=p>,</span><span class=n>set</span><span class=p>,</span><span class=n>lpush</span><span class=p>,</span><span class=n>lpop</span> <span class=o>-</span><span class=n>q</span>
<span class=nl>SET:</span> <span class=mf>35001.75</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>GET:</span> <span class=mf>37481.26</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>LPUSH:</span> <span class=mf>36968.58</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>LPOP:</span> <span class=mf>35186.49</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
</pre></div> <h2 id=geng-duo-shi-yong-pipeline-de-ce-shi>更多使用 pipeline 的测试</h2> <div class=highlight><pre><span class=err>$</span> <span class=n>redis</span><span class=o>-</span><span class=n>benchmark</span> <span class=o>-</span><span class=n>n</span> <span class=mi>100000</span>

<span class=o>======</span> <span class=n>SET</span> <span class=o>======</span>
  <span class=mi>100007</span> <span class=n>requests</span> <span class=n>completed</span> <span class=n>in</span> <span class=mf>0.88</span> <span class=n>seconds</span>
  <span class=mi>50</span> <span class=n>parallel</span> <span class=n>clients</span>
  <span class=mi>3</span> <span class=n>bytes</span> <span class=n>payload</span>
  <span class=n>keep</span> <span class=n>alive</span><span class=o>:</span> <span class=mi>1</span>

<span class=mf>58.50</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>0</span> <span class=n>milliseconds</span>
<span class=mf>99.17</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>1</span> <span class=n>milliseconds</span>
<span class=mf>99.58</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>2</span> <span class=n>milliseconds</span>
<span class=mf>99.85</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>3</span> <span class=n>milliseconds</span>
<span class=mf>99.90</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>6</span> <span class=n>milliseconds</span>
<span class=mf>100.00</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>9</span> <span class=n>milliseconds</span>
<span class=mf>114293.71</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>

<span class=o>======</span> <span class=n>GET</span> <span class=o>======</span>
  <span class=mi>100000</span> <span class=n>requests</span> <span class=n>completed</span> <span class=n>in</span> <span class=mf>1.23</span> <span class=n>seconds</span>
  <span class=mi>50</span> <span class=n>parallel</span> <span class=n>clients</span>
  <span class=mi>3</span> <span class=n>bytes</span> <span class=n>payload</span>
  <span class=n>keep</span> <span class=n>alive</span><span class=o>:</span> <span class=mi>1</span>

<span class=mf>43.12</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>0</span> <span class=n>milliseconds</span>
<span class=mf>96.82</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>1</span> <span class=n>milliseconds</span>
<span class=mf>98.62</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>2</span> <span class=n>milliseconds</span>
<span class=mf>100.00</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>3</span> <span class=n>milliseconds</span>
<span class=mf>81234.77</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>

<span class=o>======</span> <span class=n>INCR</span> <span class=o>======</span>
  <span class=mi>100018</span> <span class=n>requests</span> <span class=n>completed</span> <span class=n>in</span> <span class=mf>1.46</span> <span class=n>seconds</span>
  <span class=mi>50</span> <span class=n>parallel</span> <span class=n>clients</span>
  <span class=mi>3</span> <span class=n>bytes</span> <span class=n>payload</span>
  <span class=n>keep</span> <span class=n>alive</span><span class=o>:</span> <span class=mi>1</span>

<span class=mf>32.32</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>0</span> <span class=n>milliseconds</span>
<span class=mf>96.67</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>1</span> <span class=n>milliseconds</span>
<span class=mf>99.14</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>2</span> <span class=n>milliseconds</span>
<span class=mf>99.83</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>3</span> <span class=n>milliseconds</span>
<span class=mf>99.88</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>4</span> <span class=n>milliseconds</span>
<span class=mf>99.89</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>5</span> <span class=n>milliseconds</span>
<span class=mf>99.96</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>9</span> <span class=n>milliseconds</span>
<span class=mf>100.00</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>18</span> <span class=n>milliseconds</span>
<span class=mf>68458.59</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>

<span class=o>======</span> <span class=n>LPUSH</span> <span class=o>======</span>
  <span class=mi>100004</span> <span class=n>requests</span> <span class=n>completed</span> <span class=n>in</span> <span class=mf>1.14</span> <span class=n>seconds</span>
  <span class=mi>50</span> <span class=n>parallel</span> <span class=n>clients</span>
  <span class=mi>3</span> <span class=n>bytes</span> <span class=n>payload</span>
  <span class=n>keep</span> <span class=n>alive</span><span class=o>:</span> <span class=mi>1</span>

<span class=mf>62.27</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>0</span> <span class=n>milliseconds</span>
<span class=mf>99.74</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>1</span> <span class=n>milliseconds</span>
<span class=mf>99.85</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>2</span> <span class=n>milliseconds</span>
<span class=mf>99.86</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>3</span> <span class=n>milliseconds</span>
<span class=mf>99.89</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>5</span> <span class=n>milliseconds</span>
<span class=mf>99.93</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>7</span> <span class=n>milliseconds</span>
<span class=mf>99.96</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>9</span> <span class=n>milliseconds</span>
<span class=mf>100.00</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>22</span> <span class=n>milliseconds</span>
<span class=mf>100.00</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>208</span> <span class=n>milliseconds</span>
<span class=mf>88109.25</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>

<span class=o>======</span> <span class=n>LPOP</span> <span class=o>======</span>
  <span class=mi>100001</span> <span class=n>requests</span> <span class=n>completed</span> <span class=n>in</span> <span class=mf>1.39</span> <span class=n>seconds</span>
  <span class=mi>50</span> <span class=n>parallel</span> <span class=n>clients</span>
  <span class=mi>3</span> <span class=n>bytes</span> <span class=n>payload</span>
  <span class=n>keep</span> <span class=n>alive</span><span class=o>:</span> <span class=mi>1</span>

<span class=mf>54.83</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>0</span> <span class=n>milliseconds</span>
<span class=mf>97.34</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>1</span> <span class=n>milliseconds</span>
<span class=mf>99.95</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>2</span> <span class=n>milliseconds</span>
<span class=mf>99.96</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>3</span> <span class=n>milliseconds</span>
<span class=mf>99.96</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>4</span> <span class=n>milliseconds</span>
<span class=mf>100.00</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>9</span> <span class=n>milliseconds</span>
<span class=mf>100.00</span><span class=o>%</span> <span class=o>&lt;=</span> <span class=mi>208</span> <span class=n>milliseconds</span>
<span class=mf>71994.96</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
</pre></div> <p>注意：包大小从 256 到 1024 或者 4096 bytes 不会改变结果的量级 （但是到 1024 bytes 后，GETs 操作会变慢）。同样的，50 到 256 客户端的测试结果相同。 10 个客户端时候，吞吐量会变小（译者按：总量到不了最大吞吐量）。</p> <p>不同机器可以获的不一样的结果，下面是 <em>Intel T5500 1.66 GHz 在 Linux 2.6</em> 下面的结果：</p> <div class=highlight><pre><span class=err>$</span> <span class=p>.</span><span class=o>/</span><span class=n>redis</span><span class=o>-</span><span class=n>benchmark</span> <span class=o>-</span><span class=n>q</span> <span class=o>-</span><span class=n>n</span> <span class=mi>100000</span>
<span class=nl>SET:</span> <span class=mf>53684.38</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>GET:</span> <span class=mf>45497.73</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>INCR:</span> <span class=mf>39370.47</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>LPUSH:</span> <span class=mf>34803.41</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>LPOP:</span> <span class=mf>37367.20</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
</pre></div> <p>另外一个是 64 位 Xeon L5420 2.5 GHz 的结果：</p> <div class=highlight><pre><span class=err>$</span> <span class=p>.</span><span class=o>/</span><span class=n>redis</span><span class=o>-</span><span class=n>benchmark</span> <span class=o>-</span><span class=n>q</span> <span class=o>-</span><span class=n>n</span> <span class=mi>100000</span>
<span class=nl>PING:</span> <span class=mf>111731.84</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>SET:</span> <span class=mf>108114.59</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>GET:</span> <span class=mf>98717.67</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>INCR:</span> <span class=mf>95241.91</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>LPUSH:</span> <span class=mf>104712.05</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>LPOP:</span> <span class=mf>93722.59</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
</pre></div> <h1>高性能硬件下面的基准测试</h1> <ul> <li>Redis <strong>2.4.2</strong>。</li> <li>默认连接数，数据包大小 256 bytes。</li> <li>Linux 是 <em>SLES10 SP3 2.6.16.60-0.54.5-smp</em>，CPU 是 2 x <em>Intel X5670 @ 2.93 GHz</em>。</li> <li>固定 CPU，但是使用不同 CPU 内核。</li> </ul> <p>使用 unix domain socket：</p> <div class=highlight><pre><span class=err>$</span> <span class=n>numactl</span> <span class=o>-</span><span class=n>C</span> <span class=mi>6</span> <span class=p>.</span><span class=o>/</span><span class=n>redis</span><span class=o>-</span><span class=n>benchmark</span> <span class=o>-</span><span class=n>q</span> <span class=o>-</span><span class=n>n</span> <span class=mi>100000</span> <span class=o>-</span><span class=n>s</span> <span class=o>/</span><span class=n>tmp</span><span class=o>/</span><span class=n>redis</span><span class=p>.</span><span class=n>sock</span> <span class=o>-</span><span class=n>d</span> <span class=mi>256</span>
<span class=n>PING</span> <span class=p>(</span><span class=kr>inline</span><span class=p>)</span><span class=o>:</span> <span class=mf>200803.22</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>PING:</span> <span class=mf>200803.22</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=n>MSET</span> <span class=p>(</span><span class=mi>10</span> <span class=n>keys</span><span class=p>)</span><span class=o>:</span> <span class=mf>78064.01</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>SET:</span> <span class=mf>198412.69</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>GET:</span> <span class=mf>198019.80</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>INCR:</span> <span class=mf>200400.80</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>LPUSH:</span> <span class=mf>200000.00</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>LPOP:</span> <span class=mf>198019.80</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>SADD:</span> <span class=mf>203665.98</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>SPOP:</span> <span class=mf>200803.22</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=n>LPUSH</span> <span class=p>(</span><span class=n>again</span><span class=p>,</span> <span class=n>in</span> <span class=n>order</span> <span class=n>to</span> <span class=n>bench</span> <span class=n>LRANGE</span><span class=p>)</span><span class=o>:</span> <span class=mf>200000.00</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=n>LRANGE</span> <span class=p>(</span><span class=n>first</span> <span class=mi>100</span> <span class=n>elements</span><span class=p>)</span><span class=o>:</span> <span class=mf>42123.00</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=n>LRANGE</span> <span class=p>(</span><span class=n>first</span> <span class=mi>300</span> <span class=n>elements</span><span class=p>)</span><span class=o>:</span> <span class=mf>15015.02</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=n>LRANGE</span> <span class=p>(</span><span class=n>first</span> <span class=mi>450</span> <span class=n>elements</span><span class=p>)</span><span class=o>:</span> <span class=mf>10159.50</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=n>LRANGE</span> <span class=p>(</span><span class=n>first</span> <span class=mi>600</span> <span class=n>elements</span><span class=p>)</span><span class=o>:</span> <span class=mf>7548.31</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
</pre></div> <p>使用 TCP loopback：</p> <div class=highlight><pre><span class=err>$</span> <span class=n>numactl</span> <span class=o>-</span><span class=n>C</span> <span class=mi>6</span> <span class=p>.</span><span class=o>/</span><span class=n>redis</span><span class=o>-</span><span class=n>benchmark</span> <span class=o>-</span><span class=n>q</span> <span class=o>-</span><span class=n>n</span> <span class=mi>100000</span> <span class=o>-</span><span class=n>d</span> <span class=mi>256</span>
<span class=n>PING</span> <span class=p>(</span><span class=kr>inline</span><span class=p>)</span><span class=o>:</span> <span class=mf>145137.88</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>PING:</span> <span class=mf>144717.80</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=n>MSET</span> <span class=p>(</span><span class=mi>10</span> <span class=n>keys</span><span class=p>)</span><span class=o>:</span> <span class=mf>65487.89</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>SET:</span> <span class=mf>142653.36</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>GET:</span> <span class=mf>142450.14</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>INCR:</span> <span class=mf>143061.52</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>LPUSH:</span> <span class=mf>144092.22</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>LPOP:</span> <span class=mf>142247.52</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>SADD:</span> <span class=mf>144717.80</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=nl>SPOP:</span> <span class=mf>143678.17</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=n>LPUSH</span> <span class=p>(</span><span class=n>again</span><span class=p>,</span> <span class=n>in</span> <span class=n>order</span> <span class=n>to</span> <span class=n>bench</span> <span class=n>LRANGE</span><span class=p>)</span><span class=o>:</span> <span class=mf>143061.52</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=n>LRANGE</span> <span class=p>(</span><span class=n>first</span> <span class=mi>100</span> <span class=n>elements</span><span class=p>)</span><span class=o>:</span> <span class=mf>29577.05</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=n>LRANGE</span> <span class=p>(</span><span class=n>first</span> <span class=mi>300</span> <span class=n>elements</span><span class=p>)</span><span class=o>:</span> <span class=mf>10431.88</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=n>LRANGE</span> <span class=p>(</span><span class=n>first</span> <span class=mi>450</span> <span class=n>elements</span><span class=p>)</span><span class=o>:</span> <span class=mf>7010.66</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
<span class=n>LRANGE</span> <span class=p>(</span><span class=n>first</span> <span class=mi>600</span> <span class=n>elements</span><span class=p>)</span><span class=o>:</span> <span class=mf>5296.61</span> <span class=n>requests</span> <span class=n>per</span> <span class=n>second</span>
</pre></div> </div> <!-- /.entry-content --> <hr> <div class=panel> <div class=panel-body> <small>原文链接: <a href=https://blog.alswl.com/2014/02/redis-benchmarks/ >https://blog.alswl.com/2014/02/redis-benchmarks/</a></small><br> <small>3a1ff193cee606bd1e2ea554a16353ee</small><br> <small>欢迎关注我的微信公众号：<a href="http://mp.weixin.qq.com/mp/getmasssendmsg?__biz=MzIyNTIwMTU3MQ==#wechat_webview_type=1&wechat_redirect">窥豹</a></small><br> <small><img src=https://ohsolnxaa.qnssl.com/upload_dropbox/201605/qrcode_for_gh_17e2f9c2caa4_258.jpg></small> <small><img src=https://ohsolnxaa.qnssl.com/upload_dropbox/meta/wechat-pay-s-crop.png></small> </div> </div> <hr> <section class=comments id=comments> <h2>Comments</h2> <div id=disqus_thread></div> <script type=text/javascript>
            /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
            var disqus_shortname = 'log4d'; // required: replace example with your forum shortname

                    var disqus_identifier = 'redis-benchmarks';
                var disqus_url = 'https://blog.alswl.com/2014/02/redis-benchmarks/';

            var disqus_config = function () {
                this.language = "en";
            };

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
        </script> <noscript>Please enable JavaScript to view the <a href=http://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript> <a href=http://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a> </section> </article> </section> </div> <div class="col-lg-3 col-lg-offset-2" id=sidebar> <aside> <section> <ul class="list-group list-group-flush"> <li class=list-group-item><h4><i class="fa fa-home fa-lg"></i><span class=icon-label>Social</span></h4> <ul class=list-group id=social> <li class=list-group-item><a href=https://blog.alswl.com/atom.xml><i class="fa fa-rss-square fa-lg"></i> RSS</a></li> <li class=list-group-item><a href=https://twitter.com/alswl><i class="fa fa-twitter-square fa-lg"></i> Twitter</a></li> <li class=list-group-item><a href=https://github.com/alswl><i class="fa fa-github-square fa-lg"></i> Github</a></li> <li class=list-group-item><a href=http://weibo.com/alswlx><i class="fa fa-weibo fa-lg"></i> Weibo</a></li> </ul> </li> </ul> </section> </aside> </div> <div class=col-lg-3 id=sidebar> <aside> <section> <ul class="list-group list-group-flush"> <li class=list-group-item><a href=https://blog.alswl.com/ ><h4><i class="fa fa-home fa-lg"></i><span class=icon-label>Categories</span></h4></a> <ul class=list-group id=categories> <li class=list-group-item> <a href=https://blog.alswl.com/category/coding/ > <i class="fa fa-folder-open fa-lg"></i> Coding </a> </li> <li class=list-group-item> <a href=https://blog.alswl.com/category/efficiency/ > <i class="fa fa-folder-open fa-lg"></i> Efficiency </a> </li> <li class=list-group-item> <a href=https://blog.alswl.com/category/fun/ > <i class="fa fa-folder-open fa-lg"></i> Fun </a> </li> <li class=list-group-item> <a href=https://blog.alswl.com/category/internet/ > <i class="fa fa-folder-open fa-lg"></i> Internet </a> </li> <li class=list-group-item> <a href=https://blog.alswl.com/category/life/ > <i class="fa fa-folder-open fa-lg"></i> Life </a> </li> <li class=list-group-item> <a href=https://blog.alswl.com/category/managment/ > <i class="fa fa-folder-open fa-lg"></i> Managment </a> </li> <li class=list-group-item> <a href=https://blog.alswl.com/category/thinking/ > <i class="fa fa-folder-open fa-lg"></i> Thinking </a> </li> <li class=list-group-item> <a href=https://blog.alswl.com/category/ui/ > <i class="fa fa-folder-open fa-lg"></i> UI </a> </li> <li class=list-group-item> <a href=https://blog.alswl.com/category/viewpoint/ > <i class="fa fa-folder-open fa-lg"></i> Viewpoint </a> </li> </ul> </li> </ul> </section> </aside> </div> </div> </div> <footer> <div class=container> <hr> <div class=row> <div class=col-xs-10>&copy; 2018 alswl &middot; Powered by <a href=https://github.com/alswl/pelican-bootstrap3 target=_blank style="font-weight: bold">pelican-bootstrap3</a>, <a href=http://docs.getpelican.com/ target=_blank style="font-weight: bold">Pelican</a>, <a href=http://getbootstrap.com target=_blank style="font-weight: bold">Bootstrap</a>, Hosted by <a href=https://pages.coding.me target=_blank style="font-weight: bold">Coding Pages</a> <p><small> <a href=http://creativecommons.org/licenses/by-nc-nd/4.0/ rel=license><img alt="Creative Commons License" style=border-width:0 src=//i.creativecommons.org/l/by-nc-nd/4.0/80x15.png></a> Content licensed under a <a href=http://creativecommons.org/licenses/by-nc-nd/4.0/ rel=license>Creative Commons Attribution 4.0 International-NonCommercial-NoDerivatives License</a>, except where indicated otherwise. </small></p> </div> <div class=col-xs-2><p class=pull-right><i class="fa fa-arrow-up"></i> <a href=#>Back to top</a></p></div> </div> </div> </footer> <script src=https://blog.alswl.com/theme/js/jquery.min.js></script> <!--<script src="http://cdn.staticfile.org/jquery/2.1.1/jquery.min.js"></script>--> <!-- Include all compiled plugins (below), or include individual files as needed --> <script src=https://blog.alswl.com/theme/js/bootstrap.min.js></script> <!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) --> <script src=https://blog.alswl.com/theme/js/respond.min.js></script> <!-- Disqus --> <script type=text/javascript>
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'log4d'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function () {
            var s = document.createElement('script');
            s.async = true;
            s.type = 'text/javascript';
            s.src = '//' + disqus_shortname + '.disqus.com/count.js';
            (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
        }());
    </script> <!-- End Disqus Code --> <!-- Google Analytics --> <script type=text/javascript>

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-8822123-3']);
        _gaq.push(['_trackPageview']);

        (function () {
            var ga = document.createElement('script');
            ga.type = 'text/javascript';
            ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(ga, s);
        })();
    </script> <!-- End Google Analytics Code --> </body> </html>