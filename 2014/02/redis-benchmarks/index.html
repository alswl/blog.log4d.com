<!DOCTYPE html>
<html lang="en"
>
<head>
    <title>Redis 到底有多快[译文] - Log4D</title>
    <!-- Using the latest rendering mode for IE -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Content-Security-Policy" content="block-all-mixed-content">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />



<link rel="canonical" href="https://blog.alswl.com/2014/02/redis-benchmarks/">

        <meta name="author" content="alswl" />
        <meta name="keywords" content="性能,Redis,benchmark,译文" />
        <meta name="description" content="原文地址 http://redis.io/topics/benchmarks。 拖了一个半月的稿子~ Redis 自带了一个叫 redis-benchmark 的工具来模拟 N 个客户端同时发出 M 个请求。 （类似于 Apache ab 程序）。你可以使用 redis-benchmark -h 来查看基准参数。 以下参数被支持： Usage: redis-benchmark [-h &lt;host&gt;] [-p &lt;port&gt;] [-c &lt;clients&gt;] [-n &lt;requests]&gt; [-k &lt;boolean&gt;] -h &lt;hostname&gt; Server hostname (default 127.0.0.1) -p &lt;port&gt; Server port (default …" />



    <!-- Bootstrap -->
        <link rel="stylesheet" href="https://blog.alswl.com/theme/css/bootstrap.min.css" type="text/css"/>
    <link href="https://blog.alswl.com/theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="https://blog.alswl.com/theme/css/pygments/native.css" rel="stylesheet">
    <link rel="stylesheet" href="https://blog.alswl.com/theme/css/style.css" type="text/css"/>

    <link href="https://blog.alswl.com/atom.xml" type="application/atom+xml" rel="alternate" title="Log4D Atom Feed" />
    <link href="https://blog.alswl.com/rss.xml" type="application/rss+xml" rel="alternate" title="Log4D RSS Feed" />

</head>
<body>

<div class="navbar navbar-default" role="navigation">
    <div class="container  col-lg-8 col-lg-offset-2">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a href="https://blog.alswl.com/" class="navbar-brand">
Log4D            </a>
        </div>
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                    <li><a href="/tags/">Tags</a></li>
                    <li><a href="/links/">Links</a></li>
                    <li><a href="/about/">About</a></li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
                <li><a href="https://blog.alswl.com/archives/"><i class="fa fa-th-list"></i><span class="icon-label">Archives</span></a></li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
</div> <!-- /.navbar -->

<div class="container">
    <div class="row">
        <div class="col-lg-8 col-lg-offset-2">

    <section id="content">
        <article class="article-detail">
            <header class="page-header">
                <h1 class="title">
                    <a href="https://blog.alswl.com/2014/02/redis-benchmarks/"
                       rel="bookmark"
                       title="Permalink to Redis 到底有多快[译文]">
                        Redis 到底有多快[译文]
                    </a>
                </h1>
            </header>
            <div class="entry-content">
                <div class="panel">
                    <div class="panel-body">
<footer class="post-info">
    <span class="label label-default">Date</span>
    <span class="published">
        <i class="fa fa-calendar"></i><time datetime="2014-02-23T22:38:00+08:00"> 2014-02-23</time>
    </span>



<span class="label label-default">Tags</span>
	<a href="https://blog.alswl.com/tag/xing-neng/">性能</a>
        /
	<a href="https://blog.alswl.com/tag/redis/">Redis</a>
        /
	<a href="https://blog.alswl.com/tag/benchmark/">benchmark</a>
        /
	<a href="https://blog.alswl.com/tag/yi-wen/">译文</a>
    
</footer><!-- /.post-info -->                    </div>
                </div>
                <nav class="toc">
                  <h2>Table of Contents</h2>
                  <div id="toc"><ul><li><a class="toc-href" href="#zhi-yun-xing-yi-xie-ce-shi-yong-li-de-zi-ji" title="只运行一些测试用例的子集">只运行一些测试用例的子集</a></li><li><a class="toc-href" href="#xuan-ze-ce-shi-jian-de-fan-wei-da-xiao" title="选择测试键的范围大小">选择测试键的范围大小</a></li><li><a class="toc-href" href="#shi-yong-pipelining" title="使用 pipelining">使用 pipelining</a></li><li><a class="toc-href" href="#xian-jing-he-cuo-wu-de-ren-shi" title="陷阱和错误的认识">陷阱和错误的认识</a></li><li><a class="toc-href" href="#ying-xiang-redis-xing-neng-de-yin-su" title="影响 Redis 性能的因素">影响 Redis 性能的因素</a></li><li><a class="toc-href" href="#qi-ta-xu-yao-zhu-yi-de-dian" title="其他需要注意的点">其他需要注意的点</a></li><li><a class="toc-href" href="#geng-duo-shi-yong-pipeline-de-ce-shi" title="更多使用 pipeline 的测试">更多使用 pipeline 的测试</a></li></ul></div>
                </nav>
                <hr/>
                <p>原文地址 <a href="http://redis.io/topics/benchmarks">http://redis.io/topics/benchmarks</a>。</p>
<p>拖了一个半月的稿子~</p>
<hr/>
<p>Redis 自带了一个叫 <code>redis-benchmark</code> 的工具来模拟 N 个客户端同时发出 M 个请求。
（类似于 Apache <code>ab</code> 程序）。你可以使用 <code>redis-benchmark -h</code> 来查看基准参数。</p>
<!-- more -->
<div class="highlight"><pre><span></span>以下参数被支持：

    Usage: redis-benchmark [-h &lt;host&gt;] [-p &lt;port&gt;] [-c &lt;clients&gt;] [-n &lt;requests]&gt; [-k &lt;boolean&gt;]

     -h &lt;hostname&gt;      Server hostname (default 127.0.0.1)
     -p &lt;port&gt;          Server port (default 6379)
     -s &lt;socket&gt;        Server socket (overrides host and port)
     -c &lt;clients&gt;       Number of parallel connections (default 50)
     -n &lt;requests&gt;      Total number of requests (default 10000)
     -d &lt;size&gt;          Data size of SET/GET value in bytes (default 2)
     -k &lt;boolean&gt;       1=keep alive 0=reconnect (default 1)
     -r &lt;keyspacelen&gt;   Use random keys for SET/GET/INCR, random values for SADD
      Using this option the benchmark will get/set keys
      in the form mykey_rand:000000012456 instead of constant
      keys, the &lt;keyspacelen&gt; argument determines the max
      number of values for the random number. For instance
      if set to 10 only rand:000000000000 - rand:000000000009
      range will be allowed.
     -P &lt;numreq&gt;        Pipeline &lt;numreq&gt; requests. Default 1 (no pipeline).
     -q                 Quiet. Just show query/sec values
     --csv              Output in CSV format
     -l                 Loop. Run the tests forever
     -t &lt;tests&gt;         Only run the comma separated list of tests. The test
                        names are the same as the ones produced as output.
     -I                 Idle mode. Just open N idle connections and wait.
</pre></div>
<p>你需要在基准测试之前启动一个 Redis 实例。一般这样启动测试：</p>
<div class="highlight"><pre><span></span>redis-benchmark -q -n 100000
</pre></div>
<p>这个工具使用起来非常方便，同时你可以使用自己的基准测试工具，
不过开始基准测试时候，我们需要注意一些细节。</p>
<h2 id="zhi-yun-xing-yi-xie-ce-shi-yong-li-de-zi-ji">只运行一些测试用例的子集</h2>
<p>你不必每次都运行 redis-benchmark 默认的所有测试。
使用 <code>-t</code> 参数可以选择你需要运行的测试用例，比如下面的范例：</p>
<div class="highlight"><pre><span></span>$ redis-benchmark -t set,lpush -n <span class="m">100000</span> -q
SET: <span class="m">74239</span>.05 requests per second
LPUSH: <span class="m">79239</span>.30 requests per second
</pre></div>
<p>在上面的测试中，我们只运行了 SET 和 LPUSH 命令，
并且运行在安静模式中（使用 <code>-q</code> 参数）。</p>
<p>也可以直接指定命令来直接运行，比如下面的范例：</p>
<div class="highlight"><pre><span></span>$ redis-benchmark -n <span class="m">100000</span> -q script load <span class="s2">"redis.call('set','foo','bar')"</span>
script load redis.call<span class="o">(</span><span class="s1">'set'</span>,<span class="s1">'foo'</span>,<span class="s1">'bar'</span><span class="o">)</span>: <span class="m">69881</span>.20 requests per second
</pre></div>
<h2 id="xuan-ze-ce-shi-jian-de-fan-wei-da-xiao">选择测试键的范围大小</h2>
<p>默认情况下面，基准测试使用单一的 key。在一个基于内存的数据库里，
单一 key 测试和真实情况下面不会有巨大变化。当然，使用一个大的 key 范围空间，
可以模拟现实情况下面的缓存不命中情况。</p>
<p>这时候我们可以使用 <code>-r</code> 命令。比如，假设我们想设置 10 万随机 key
连续 SET 100 万次，我们可以使用下列的命令：</p>
<div class="highlight"><pre><span></span>$ redis-cli flushall
OK

$ redis-benchmark -t <span class="nb">set</span> -r <span class="m">100000</span> -n <span class="nv">1000000</span>
<span class="o">======</span> <span class="nv">SET</span> <span class="o">======</span>
  <span class="m">1000000</span> requests completed in <span class="m">13</span>.86 seconds
  <span class="m">50</span> parallel clients
  <span class="m">3</span> bytes payload
  keep alive: <span class="m">1</span>

<span class="m">99</span>.76% <span class="sb">`</span>&lt;<span class="o">=</span><span class="sb">`</span> <span class="m">1</span> milliseconds
<span class="m">99</span>.98% <span class="sb">`</span>&lt;<span class="o">=</span><span class="sb">`</span> <span class="m">2</span> milliseconds
<span class="m">100</span>.00% <span class="sb">`</span>&lt;<span class="o">=</span><span class="sb">`</span> <span class="m">3</span> milliseconds
<span class="m">100</span>.00% <span class="sb">`</span>&lt;<span class="o">=</span><span class="sb">`</span> <span class="m">3</span> milliseconds
<span class="m">72144</span>.87 requests per second

$ redis-cli dbsize
<span class="o">(</span>integer<span class="o">)</span> <span class="m">99993</span>
</pre></div>
<h2 id="shi-yong-pipelining">使用 pipelining</h2>
<p>默认情况下，每个客户端都是在一个请求完成之后才发送下一个请求
（benchmark 会模拟 50 个客户端除非使用 <code>-c</code> 指定特别的数量），
这意味着服务器几乎是按顺序读取每个客户端的命令。Also RTT is payed as well.</p>
<p>真实世界会更复杂，Redis 支持
<a href="pipelining">/topics/pipelining</a>，使得可以一次性执行多条命令成为可能。
Redis pipelining 可以提高服务器的 TPS。</p>
<p>下面这个案例是在 Macbook air 11" 上使用 pipelining 组织
16 条命令的测试范例：</p>
<div class="highlight"><pre><span></span>$ redis-benchmark -n <span class="m">1000000</span> -t set,get -P <span class="m">16</span> -q
SET: <span class="m">403063</span>.28 requests per second
GET: <span class="m">508388</span>.41 requests per second
</pre></div>
<p>记得在多条命令需要处理时候使用 pipelining。</p>
<h2 id="xian-jing-he-cuo-wu-de-ren-shi">陷阱和错误的认识</h2>
<p>第一点是显而易见的：基准测试的黄金准则是使用相同的标准。
用相同的任务量测试不同版本的 Redis，或者用相同的参数测试测试不同版本 Redis。
如果把 Redis 和其他工具测试，那就需要小心功能细节差异。</p>
<ul>
<li>Redis 是一个服务器：所有的命令都包含网络或 IPC 消耗。这意味着和它和 SQLite，
Berkeley DB， Tokyo/Kyoto Cabinet 等比较起来无意义，
因为大部分的消耗都在网络协议上面。</li>
<li>Redis 的大部分常用命令都有确认返回。有些数据存储系统则没有（比如 MongoDB
的写操作没有返回确认）。把 Redis 和其他单向调用命令存储系统比较意义不大。</li>
<li>简单的循环操作 Redis 其实不是对 Redis 进行基准测试，而是测试你的网络（或者
IPC）延迟。想要真正测试 Redis，需要使用多个连接（比如 redis-benchmark)，
或者使用 pipelining 来聚合多个命令，另外还可以采用多线程或多进程。</li>
<li>Redis 是一个内存数据库，同时提供一些可选的持久化功能。
如果你想和一个持久化服务器（MySQL, PostgreSQL 等等） 对比的话，
那你需要考虑启用 AOF 和适当的 fsync 策略。</li>
<li>Redis 是单线程服务。它并没有设计为多 CPU 进行优化。如果想要从多核获取好处，
那就考虑启用多个实例吧。将单实例 Redis 和多线程数据库对比是不公平的。</li>
</ul>
<p>一个普遍的误解是 redis-benchmark 特意让基准测试看起来更好，
所表现出来的数据像是人造的，而不是真实产品下面的。</p>
<p>Redis-benchmark 程序可以简单快捷的对给定硬件条件下面的机器计算出性能参数。
但是，通常情况下面这并不是 Redis 服务器可以达到的最大吞吐量。
事实上，使用 pipelining 和更快的客户端（hiredis）可以达到更大的吞吐量。
redis-benchmark 默认情况下面仅仅使用并发来提高吞吐量（创建多条连接）。
它并没有使用 pipelining 或者其他并行技术（仅仅多条连接，而不是多线程）。</p>
<p>如果想使用 pipelining 模式来进行基准测试（了达到更高吞吐量），可以使用 <code>-P</code>
参数。这种方案的确可以提高性能，有很多使用 Redis 的应用在生产环境中这样做。</p>
<p>最后，基准测试需要使用相同的操作和数据来对比，如果这些不一样，
那么基准测试是无意义的。</p>
<p>比如，Redis 和 memcached 可以在单线程模式下面对比 GET/SET 操作。
两者都是内存数据库，协议也基本相同，甚至把多个请求合并为一条请求的方式也类似
（pipelining）。在使用相同数量的连接后，这个对比是很有意义的。</p>
<p>下面这个很不错例子是在 Redis（antirez）和 memcached（dormando）测试的。</p>
<p><a href="http://antirez.com/post/redis-memcached-benchmark.html">antirez 1 - On Redis, Memcached, Speed, Benchmarks and The Toilet</a></p>
<p><a href="http://dormando.livejournal.com/525147.html">dormando - Redis VS Memcached (slightly better bench)</a></p>
<p><a href="http://antirez.com/post/update-on-memcached-redis-benchmark.html">antirez 2 - An update on the Memcached/Redis benchmark</a></p>
<p>你可以发现相同条件下面最终结果是两者差别不大。请注意最终测试时候，
两者都经过了充分优化。</p>
<p>最后，当特别高性能的服务器在基准测试时候（比如 Redis、memcached 这类），
很难让服务器性能充分发挥，通常情况下，客户端回事瓶颈限制而不是服务器端。
在这种情况下面，客户端（比如 benchmark 程序自身）需要优化，或者使用多实例，
从而能达到最大的吞吐量。</p>
<h2 id="ying-xiang-redis-xing-neng-de-yin-su">影响 Redis 性能的因素</h2>
<p>有几个因素直接决定 Redis 的性能。它们能够改变基准测试的结果，
所以我们必须注意到它们。一般情况下，Redis 默认参数已经可以提供足够的性能，
不需要调优。</p>
<ul>
<li>网络带宽和延迟通常是最大短板。建议在基准测试之前使用
ping 来检查服务端到客户端的延迟。根据带宽，可以计算出最大吞吐量。
比如将 4 KB 的字符串塞入 Redis，吞吐量是 100000 q/s，那么实际需要 3.2 Gbits/s
的带宽，所以需要 10 GBits/s 网络连接， 1 Gbits/s 是不够的。
在很多线上服务中，Redis 吞吐会先被网络带宽限制住，而不是 CPU。
为了达到高吞吐量突破 TCP/IP 限制，最后采用 10 Gbits/s 的网卡，
或者多个 1 Gbits/s 网卡。</li>
<li>CPU 是另外一个重要的影响因素，由于是单线程模型，Redis 更喜欢大缓存快速 CPU，
而不是多核。这种场景下面，比较推荐 Intel CPU。AMD CPU 可能只有 Intel CPU
的一半性能（通过对 Nehalem EP/Westmere EP/Sandy 平台的对比）。
当其他条件相当时候，CPU 就成了 redis-benchmark 的限制因素。</li>
<li>在小对象存取时候，内存速度和带宽看上去不是很重要，但是对大对象（&gt; 10 KB），
它就变得重要起来。不过通常情况下面，倒不至于为了优化 Redis 而购买更高性能的内存模块。</li>
<li>Redis 在 VM 上会变慢。虚拟化对普通操作会有额外的消耗，Redis
对系统调用和网络终端不会有太多的 overhead。建议把 Redis 运行在物理机器上，
特别是当你很在意延迟时候。在最先进的虚拟化设备（VMWare）上面，redis-benchmark
的测试结果比物理机器上慢了一倍，很多 CPU 时间被消费在系统调用和中断上面。</li>
<li>如果服务器和客户端都运行在同一个机器上面，那么 TCP/IP loopback 和 unix domain sockets
都可以使用。对 Linux 来说，使用 unix socket 可以比 TCP/IP loopback 快 50%。
默认 redis-benchmark 是使用 TCP/IP loopback。</li>
<li>当大量使用 pipelining 时候，unix domain sockets 的优势就不那么明显了。</li>
<li>当使用网络连接时，并且以太网网数据包在 1500 bytes 以下时，
将多条命令包装成 pipelining 可以大大提高效率。事实上，处理 10 bytes，100 bytes，
1000 bytes 的请求时候，吞吐量是差不多的，详细可以见下图。</li>
</ul>
<p><img alt="Data size impact" src="https://raw.githubusercontent.com/dspezia/redis-doc/client_command/topics/Data_size.png"/></p>
<ul>
<li>在多核 CPU 服务器上面，Redis 的性能还依赖 NUMA 配置和 处理器绑定位置。
最明显的影响是 redis-benchmark 会随机使用 CPU 内核。为了获得精准的结果，
需要使用固定处理器工具（在 Linux 上可以使用 taskset 或 numactl）。
最有效的办法是将客户端和服务端分离到两个不同的 CPU 来高校使用三级缓存。
这里有一些使用 4 KB 数据 SET 的基准测试，针对三种 CPU（AMD Istanbul,
Intel Nehalem EX， 和 Intel Westmere）使用不同的配置。请注意，
这不是针对 CPU 的测试。</li>
</ul>
<p><img alt="NUMA chart" src="https://raw.githubusercontent.com/dspezia/redis-doc/6374a07f93e867353e5e946c1e39a573dfc83f6c/topics/NUMA_chart.gif"/></p>
<ul>
<li>在高配置下面，客户端的连接数也是一个重要的因素。得益于 epoll/kqueue，
Redis 的事件循环具有相当可扩展性。Redis 已经在超过 60000 连接下面基准测试过，
仍然可以维持 50000 q/s。一条经验法则是，30000 的连接数只有 100 连接的一半吞吐量。
下面有一个关于连接数和吞吐量的测试。</li>
</ul>
<p><img alt="connections chart" src="https://raw.githubusercontent.com/dspezia/redis-doc/system_info/topics/Connections_chart.png"/></p>
<ul>
<li>在高配置下面，可以通过调优 NIC 来获得更高性能。最高性能在绑定 Rx/Tx 队列和
CPU 内核下面才能达到，还需要开启 RPS（网卡中断负载均衡）。更多信息可以在
<a href="https://groups.google.com/forum/#!msg/redis-db/gUhc19gnYgc/BruTPCOroiMJ">thread</a>
。Jumbo frames 还可以在大对象使用时候获得更高性能。</li>
<li>在不同平台下面，Redis 可以被编译成不同的内存分配方式（libc malloc, jemalloc,
tcmalloc），他们在不同速度、连续和非连续片段下会有不一样的表现。
如果你不是自己编译的 Redis，可以使用 INFO 命令来检查内存分配方式。
请注意，大部分基准测试不会长时间运行来感知不同分配模式下面的差异，
只能通过生产环境下面的 Redis 实例来查看。</li>
</ul>
<h2 id="qi-ta-xu-yao-zhu-yi-de-dian">其他需要注意的点</h2>
<p>任何基准测试的一个重要目标是获得可重现的结果，这样才能将此和其他测试进行对比。</p>
<ul>
<li>一个好的实践是尽可能在隔离的硬件上面测试。如果没法实现，那就需要检测
benchmark 没有受其他服务器活动影响。</li>
<li>有些配置（桌面环境和笔记本，有些服务器也会）会使用可变的 CPU 分配策略。
这种策略可以在 OS 层面配置。有些 CPU 型号相对其他能更好的调整 CPU 负载。
为了达到可重现的测试结果，最好在做基准测试时候设定 CPU 到最高使用限制。</li>
<li>一个重要因素是配置尽可能大内存，千万不要使用 SWAP。注意 32 位和 64
位 Redis 有不同的内存限制。</li>
<li>如果你计划在基准测试时候使用 RDB 或 AOF，请注意不要让系统同时有其他 I/O 操作。
避免将 RDB 或 AOF 文件放到 NAS 或 NFS 共享或其他依赖网络的存储设备上面（比如
Amazon EC2 上 的 EBS）。</li>
<li>将 Redis 日志级别设置到 warning 或者 notice。避免将日志放到远程文件系统。</li>
<li>避免使用检测工具，它们会影响基准测试结果。使用 INFO 来查看服务器状态没问题，
但是使用 MONITOR 将大大影响测试准确度。</li>
</ul>
<h1>不同云主机和物理机器上的基准测试结果</h1>
<ul>
<li>这些测试模拟了 50 客户端和 200w 请求。</li>
<li>使用了 Redis 2.6.14。</li>
<li>使用了 loopback 网卡。</li>
<li>key 的范围是 100 w。</li>
<li>同时测试了 有 pipelining 和没有的情况（16 条命令使用 pipelining）。</li>
</ul>
<p><strong>Intel(R) Xeon(R) CPU E5520  @ 2.27GHz (with pipelining)</strong></p>
<div class="highlight"><pre><span></span>$ ./redis-benchmark -r <span class="m">1000000</span> -n <span class="m">2000000</span> -t get,set,lpush,lpop -P <span class="m">16</span> -q
SET: <span class="m">552028</span>.75 requests per second
GET: <span class="m">707463</span>.75 requests per second
LPUSH: <span class="m">767459</span>.75 requests per second
LPOP: <span class="m">770119</span>.38 requests per second
</pre></div>
<p><strong>Intel(R) Xeon(R) CPU E5520  @ 2.27GHz (without pipelining)</strong></p>
<div class="highlight"><pre><span></span>$ ./redis-benchmark -r <span class="m">1000000</span> -n <span class="m">2000000</span> -t get,set,lpush,lpop -q
SET: <span class="m">122556</span>.53 requests per second
GET: <span class="m">123601</span>.76 requests per second
LPUSH: <span class="m">136752</span>.14 requests per second
LPOP: <span class="m">132424</span>.03 requests per second
</pre></div>
<p><strong>Linode 2048 instance (with pipelining)</strong></p>
<div class="highlight"><pre><span></span>$ ./redis-benchmark -r <span class="m">1000000</span> -n <span class="m">2000000</span> -t get,set,lpush,lpop -q -P <span class="m">16</span>
SET: <span class="m">195503</span>.42 requests per second
GET: <span class="m">250187</span>.64 requests per second
LPUSH: <span class="m">230547</span>.55 requests per second
LPOP: <span class="m">250815</span>.16 requests per second
</pre></div>
<p><strong>Linode 2048 instance (without pipelining)</strong></p>
<div class="highlight"><pre><span></span>$ ./redis-benchmark -r <span class="m">1000000</span> -n <span class="m">2000000</span> -t get,set,lpush,lpop -q
SET: <span class="m">35001</span>.75 requests per second
GET: <span class="m">37481</span>.26 requests per second
LPUSH: <span class="m">36968</span>.58 requests per second
LPOP: <span class="m">35186</span>.49 requests per second
</pre></div>
<h2 id="geng-duo-shi-yong-pipeline-de-ce-shi">更多使用 pipeline 的测试</h2>
<div class="highlight"><pre><span></span>$ redis-benchmark -n <span class="nv">100000</span>

<span class="o">======</span> <span class="nv">SET</span> <span class="o">======</span>
  <span class="m">100007</span> requests completed in <span class="m">0</span>.88 seconds
  <span class="m">50</span> parallel clients
  <span class="m">3</span> bytes payload
  keep alive: <span class="m">1</span>

<span class="m">58</span>.50% &lt;<span class="o">=</span> <span class="m">0</span> milliseconds
<span class="m">99</span>.17% &lt;<span class="o">=</span> <span class="m">1</span> milliseconds
<span class="m">99</span>.58% &lt;<span class="o">=</span> <span class="m">2</span> milliseconds
<span class="m">99</span>.85% &lt;<span class="o">=</span> <span class="m">3</span> milliseconds
<span class="m">99</span>.90% &lt;<span class="o">=</span> <span class="m">6</span> milliseconds
<span class="m">100</span>.00% &lt;<span class="o">=</span> <span class="m">9</span> milliseconds
<span class="m">114293</span>.71 requests per <span class="nv">second</span>

<span class="o">======</span> <span class="nv">GET</span> <span class="o">======</span>
  <span class="m">100000</span> requests completed in <span class="m">1</span>.23 seconds
  <span class="m">50</span> parallel clients
  <span class="m">3</span> bytes payload
  keep alive: <span class="m">1</span>

<span class="m">43</span>.12% &lt;<span class="o">=</span> <span class="m">0</span> milliseconds
<span class="m">96</span>.82% &lt;<span class="o">=</span> <span class="m">1</span> milliseconds
<span class="m">98</span>.62% &lt;<span class="o">=</span> <span class="m">2</span> milliseconds
<span class="m">100</span>.00% &lt;<span class="o">=</span> <span class="m">3</span> milliseconds
<span class="m">81234</span>.77 requests per <span class="nv">second</span>

<span class="o">======</span> <span class="nv">INCR</span> <span class="o">======</span>
  <span class="m">100018</span> requests completed in <span class="m">1</span>.46 seconds
  <span class="m">50</span> parallel clients
  <span class="m">3</span> bytes payload
  keep alive: <span class="m">1</span>

<span class="m">32</span>.32% &lt;<span class="o">=</span> <span class="m">0</span> milliseconds
<span class="m">96</span>.67% &lt;<span class="o">=</span> <span class="m">1</span> milliseconds
<span class="m">99</span>.14% &lt;<span class="o">=</span> <span class="m">2</span> milliseconds
<span class="m">99</span>.83% &lt;<span class="o">=</span> <span class="m">3</span> milliseconds
<span class="m">99</span>.88% &lt;<span class="o">=</span> <span class="m">4</span> milliseconds
<span class="m">99</span>.89% &lt;<span class="o">=</span> <span class="m">5</span> milliseconds
<span class="m">99</span>.96% &lt;<span class="o">=</span> <span class="m">9</span> milliseconds
<span class="m">100</span>.00% &lt;<span class="o">=</span> <span class="m">18</span> milliseconds
<span class="m">68458</span>.59 requests per <span class="nv">second</span>

<span class="o">======</span> <span class="nv">LPUSH</span> <span class="o">======</span>
  <span class="m">100004</span> requests completed in <span class="m">1</span>.14 seconds
  <span class="m">50</span> parallel clients
  <span class="m">3</span> bytes payload
  keep alive: <span class="m">1</span>

<span class="m">62</span>.27% &lt;<span class="o">=</span> <span class="m">0</span> milliseconds
<span class="m">99</span>.74% &lt;<span class="o">=</span> <span class="m">1</span> milliseconds
<span class="m">99</span>.85% &lt;<span class="o">=</span> <span class="m">2</span> milliseconds
<span class="m">99</span>.86% &lt;<span class="o">=</span> <span class="m">3</span> milliseconds
<span class="m">99</span>.89% &lt;<span class="o">=</span> <span class="m">5</span> milliseconds
<span class="m">99</span>.93% &lt;<span class="o">=</span> <span class="m">7</span> milliseconds
<span class="m">99</span>.96% &lt;<span class="o">=</span> <span class="m">9</span> milliseconds
<span class="m">100</span>.00% &lt;<span class="o">=</span> <span class="m">22</span> milliseconds
<span class="m">100</span>.00% &lt;<span class="o">=</span> <span class="m">208</span> milliseconds
<span class="m">88109</span>.25 requests per <span class="nv">second</span>

<span class="o">======</span> <span class="nv">LPOP</span> <span class="o">======</span>
  <span class="m">100001</span> requests completed in <span class="m">1</span>.39 seconds
  <span class="m">50</span> parallel clients
  <span class="m">3</span> bytes payload
  keep alive: <span class="m">1</span>

<span class="m">54</span>.83% &lt;<span class="o">=</span> <span class="m">0</span> milliseconds
<span class="m">97</span>.34% &lt;<span class="o">=</span> <span class="m">1</span> milliseconds
<span class="m">99</span>.95% &lt;<span class="o">=</span> <span class="m">2</span> milliseconds
<span class="m">99</span>.96% &lt;<span class="o">=</span> <span class="m">3</span> milliseconds
<span class="m">99</span>.96% &lt;<span class="o">=</span> <span class="m">4</span> milliseconds
<span class="m">100</span>.00% &lt;<span class="o">=</span> <span class="m">9</span> milliseconds
<span class="m">100</span>.00% &lt;<span class="o">=</span> <span class="m">208</span> milliseconds
<span class="m">71994</span>.96 requests per second
</pre></div>
<p>注意：包大小从 256 到 1024 或者 4096 bytes 不会改变结果的量级
（但是到 1024 bytes 后，GETs 操作会变慢）。同样的，50 到 256 客户端的测试结果相同。
10 个客户端时候，吞吐量会变小（译者按：总量到不了最大吞吐量）。</p>
<p>不同机器可以获的不一样的结果，下面是 <em>Intel T5500 1.66 GHz 在 Linux 2.6</em>
下面的结果：</p>
<div class="highlight"><pre><span></span>$ ./redis-benchmark -q -n <span class="m">100000</span>
SET: <span class="m">53684</span>.38 requests per second
GET: <span class="m">45497</span>.73 requests per second
INCR: <span class="m">39370</span>.47 requests per second
LPUSH: <span class="m">34803</span>.41 requests per second
LPOP: <span class="m">37367</span>.20 requests per second
</pre></div>
<p>另外一个是 64 位 Xeon L5420 2.5 GHz 的结果：</p>
<div class="highlight"><pre><span></span>$ ./redis-benchmark -q -n <span class="m">100000</span>
PING: <span class="m">111731</span>.84 requests per second
SET: <span class="m">108114</span>.59 requests per second
GET: <span class="m">98717</span>.67 requests per second
INCR: <span class="m">95241</span>.91 requests per second
LPUSH: <span class="m">104712</span>.05 requests per second
LPOP: <span class="m">93722</span>.59 requests per second
</pre></div>
<h1>高性能硬件下面的基准测试</h1>
<ul>
<li>Redis <strong>2.4.2</strong>。</li>
<li>默认连接数，数据包大小 256 bytes。</li>
<li>Linux 是 <em>SLES10 SP3 2.6.16.60-0.54.5-smp</em>，CPU 是 2 x <em>Intel X5670 @ 2.93 GHz</em>。</li>
<li>固定 CPU，但是使用不同 CPU 内核。</li>
</ul>
<p>使用 unix domain socket：</p>
<div class="highlight"><pre><span></span>$ numactl -C <span class="m">6</span> ./redis-benchmark -q -n <span class="m">100000</span> -s /tmp/redis.sock -d <span class="m">256</span>
PING <span class="o">(</span>inline<span class="o">)</span>: <span class="m">200803</span>.22 requests per second
PING: <span class="m">200803</span>.22 requests per second
MSET <span class="o">(</span><span class="m">10</span> keys<span class="o">)</span>: <span class="m">78064</span>.01 requests per second
SET: <span class="m">198412</span>.69 requests per second
GET: <span class="m">198019</span>.80 requests per second
INCR: <span class="m">200400</span>.80 requests per second
LPUSH: <span class="m">200000</span>.00 requests per second
LPOP: <span class="m">198019</span>.80 requests per second
SADD: <span class="m">203665</span>.98 requests per second
SPOP: <span class="m">200803</span>.22 requests per second
LPUSH <span class="o">(</span>again, in order to bench LRANGE<span class="o">)</span>: <span class="m">200000</span>.00 requests per second
LRANGE <span class="o">(</span>first <span class="m">100</span> elements<span class="o">)</span>: <span class="m">42123</span>.00 requests per second
LRANGE <span class="o">(</span>first <span class="m">300</span> elements<span class="o">)</span>: <span class="m">15015</span>.02 requests per second
LRANGE <span class="o">(</span>first <span class="m">450</span> elements<span class="o">)</span>: <span class="m">10159</span>.50 requests per second
LRANGE <span class="o">(</span>first <span class="m">600</span> elements<span class="o">)</span>: <span class="m">7548</span>.31 requests per second
</pre></div>
<p>使用 TCP loopback：</p>
<div class="highlight"><pre><span></span>$ numactl -C <span class="m">6</span> ./redis-benchmark -q -n <span class="m">100000</span> -d <span class="m">256</span>
PING <span class="o">(</span>inline<span class="o">)</span>: <span class="m">145137</span>.88 requests per second
PING: <span class="m">144717</span>.80 requests per second
MSET <span class="o">(</span><span class="m">10</span> keys<span class="o">)</span>: <span class="m">65487</span>.89 requests per second
SET: <span class="m">142653</span>.36 requests per second
GET: <span class="m">142450</span>.14 requests per second
INCR: <span class="m">143061</span>.52 requests per second
LPUSH: <span class="m">144092</span>.22 requests per second
LPOP: <span class="m">142247</span>.52 requests per second
SADD: <span class="m">144717</span>.80 requests per second
SPOP: <span class="m">143678</span>.17 requests per second
LPUSH <span class="o">(</span>again, in order to bench LRANGE<span class="o">)</span>: <span class="m">143061</span>.52 requests per second
LRANGE <span class="o">(</span>first <span class="m">100</span> elements<span class="o">)</span>: <span class="m">29577</span>.05 requests per second
LRANGE <span class="o">(</span>first <span class="m">300</span> elements<span class="o">)</span>: <span class="m">10431</span>.88 requests per second
LRANGE <span class="o">(</span>first <span class="m">450</span> elements<span class="o">)</span>: <span class="m">7010</span>.66 requests per second
LRANGE <span class="o">(</span>first <span class="m">600</span> elements<span class="o">)</span>: <span class="m">5296</span>.61 requests per second
</pre></div>
            </div>
            <!-- /.entry-content -->
              
<hr>
<div class="panel">
<div class="panel-body">
   <small>原文链接: <a href="https://blog.alswl.com/2014/02/redis-benchmarks/">https://blog.alswl.com/2014/02/redis-benchmarks/</a></small><br>
   <small>欢迎关注我的微信公众号：<a href="http://mp.weixin.qq.com/mp/getmasssendmsg?__biz=MzIyNTIwMTU3MQ==#wechat_webview_type=1&wechat_redirect">窥豹</a></small><br>
   <small><img src="https://ohsolnxaa.qnssl.com/upload_dropbox/201605/qrcode_for_gh_17e2f9c2caa4_258.jpg"/></small><br>
   <small>3a1ff193cee606bd1e2ea554a16353ee</small>
</div>
</div>

    <hr/>
    <section class="comments" id="comments">
        <h2>Comments</h2>

        <div id="disqus_thread"></div>
        <script type="text/javascript">
            /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
            var disqus_shortname = 'log4d'; // required: replace example with your forum shortname

                    var disqus_identifier = 'redis-benchmarks';
                var disqus_url = 'https://blog.alswl.com/2014/02/redis-benchmarks/';

            var disqus_config = function () {
                this.language = "en";
            };

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
        </script>
		<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
		<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
    

    </section>
        </article>
    </section>

        </div>
        <div class="col-lg-3 col-lg-offset-2" id="sidebar">

<aside>
    <section>
        <ul class="list-group list-group-flush">
                <li class="list-group-item"><h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Social</span></h4>
                  <ul class="list-group" id="social">
                    <li class="list-group-item"><a href="https://blog.alswl.com/atom.xml"><i class="fa fa-rss-square fa-lg"></i> RSS</a></li>
                    <li class="list-group-item"><a href="https://twitter.com/alswl"><i class="fa fa-twitter-square fa-lg"></i> Twitter</a></li>
                    <li class="list-group-item"><a href="https://github.com/alswl"><i class="fa fa-github-square fa-lg"></i> Github</a></li>
                    <li class="list-group-item"><a href="http://weibo.com/alswlx"><i class="fa fa-weibo fa-lg"></i> Weibo</a></li>
                  </ul>
                </li>




        </ul>
    </section>

</aside>        </div>
    <div class="col-lg-3" id="sidebar">
<aside>
    <section>
        <ul class="list-group list-group-flush">
                <li class="list-group-item"><a href="https://blog.alswl.com/"><h4><i class="fa fa-home fa-lg"></i><span class="icon-label">Categories</span></h4></a>
                    <ul class="list-group" id="categories">
                        <li class="list-group-item">
                            <a href="https://blog.alswl.com/category/coding/">
                                <i class="fa fa-folder-open fa-lg"></i> Coding
                            </a>
                        </li>
                        <li class="list-group-item">
                            <a href="https://blog.alswl.com/category/efficiency/">
                                <i class="fa fa-folder-open fa-lg"></i> Efficiency
                            </a>
                        </li>
                        <li class="list-group-item">
                            <a href="https://blog.alswl.com/category/fun/">
                                <i class="fa fa-folder-open fa-lg"></i> Fun
                            </a>
                        </li>
                        <li class="list-group-item">
                            <a href="https://blog.alswl.com/category/internet/">
                                <i class="fa fa-folder-open fa-lg"></i> Internet
                            </a>
                        </li>
                        <li class="list-group-item">
                            <a href="https://blog.alswl.com/category/life/">
                                <i class="fa fa-folder-open fa-lg"></i> Life
                            </a>
                        </li>
                        <li class="list-group-item">
                            <a href="https://blog.alswl.com/category/managment/">
                                <i class="fa fa-folder-open fa-lg"></i> Managment
                            </a>
                        </li>
                        <li class="list-group-item">
                            <a href="https://blog.alswl.com/category/misc/">
                                <i class="fa fa-folder-open fa-lg"></i> misc
                            </a>
                        </li>
                        <li class="list-group-item">
                            <a href="https://blog.alswl.com/category/thinking/">
                                <i class="fa fa-folder-open fa-lg"></i> Thinking
                            </a>
                        </li>
                        <li class="list-group-item">
                            <a href="https://blog.alswl.com/category/ui/">
                                <i class="fa fa-folder-open fa-lg"></i> UI
                            </a>
                        </li>
                        <li class="list-group-item">
                            <a href="https://blog.alswl.com/category/viewpoint/">
                                <i class="fa fa-folder-open fa-lg"></i> Viewpoint
                            </a>
                        </li>
                    </ul>
                </li>


        </ul>
    </section>

</aside>    </div>
    </div>
</div>
<footer>
   <div class="container">
      <hr>
      <div class="row">
         <div class="col-xs-10">&copy; 2017 alswl
            &middot; Powered by <a href="https://github.com/alswl/pelican-bootstrap3" target="_blank" style="font-weight: bold">pelican-bootstrap3</a>,
            <a href="http://docs.getpelican.com/" target="_blank" style="font-weight: bold">Pelican</a>,
            <a href="http://getbootstrap.com" target="_blank" style="font-weight: bold">Bootstrap</a>,
            Hosted by <a href="https://pages.coding.me" target="_blank" style="font-weight: bold">Coding Pages</a>              <p><small>  <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="//i.creativecommons.org/l/by-nc-nd/4.0/80x15.png" /></a>
    Content
  licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/">Creative Commons Attribution 4.0 International-NonCommercial-NoDerivatives License</a>, except where indicated otherwise.
</small></p>
         </div>
         <div class="col-xs-2"><p class="pull-right"><i class="fa fa-arrow-up"></i> <a href="#">Back to top</a></p></div>
      </div>
   </div>
</footer>
<script src="https://blog.alswl.com/theme/js/jquery.min.js"></script>
<!--<script src="http://cdn.staticfile.org/jquery/2.1.1/jquery.min.js"></script>-->

<!-- Include all compiled plugins (below), or include individual files as needed -->
<script src="https://blog.alswl.com/theme/js/bootstrap.min.js"></script>

<!-- Enable responsive features in IE8 with Respond.js (https://github.com/scottjehl/Respond) -->
<script src="https://blog.alswl.com/theme/js/respond.min.js"></script>

    <!-- Disqus -->
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'log4d'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function () {
            var s = document.createElement('script');
            s.async = true;
            s.type = 'text/javascript';
            s.src = '//' + disqus_shortname + '.disqus.com/count.js';
            (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
        }());
    </script>
    <!-- End Disqus Code -->
    <!-- Google Analytics -->
    <script type="text/javascript">

        var _gaq = _gaq || [];
        _gaq.push(['_setAccount', 'UA-8822123-3']);
        _gaq.push(['_trackPageview']);

        (function () {
            var ga = document.createElement('script');
            ga.type = 'text/javascript';
            ga.async = true;
            ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(ga, s);
        })();
    </script>
    <!-- End Google Analytics Code -->
</body>
</html>